python3 main.py \
    --llm_path llms/llama_c++/models/llama-2-7b.Q2_K.gguf \
    --benchmarks mbpp\
    --max_tokens 512 \
    --n_ctx 4098 \
    --seed 42 \
    --top_p 0.95 \
    --temperature 0.6 \
    --n_times 1 \
    --sleep_time 1.0 \
    --save_output no \
    --n_shot_prompting 1 \
    --pass_k 1 \
    --samples_interval 1