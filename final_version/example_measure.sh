python3 main.py \
    --llm_path llama_c++/models/llama-2-7b.Q2_K.gguf \
    --benchmarks cyberseceval/mitre \
    --max_tokens 512

    