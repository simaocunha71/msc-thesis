python3 main.py \
    --llm_path llms/models/Meta-Llama-3-8B-Instruct-Q6_K.gguf \
    --benchmarks mbpp \
    --max_tokens 512 \
    --n_ctx 4098 \
    --seed 42 \
    --top_p 0.95 \
    --temperature 0.6 \
    --n_times 1 \
    --sleep_time 1.0 \
    --save_output yes \
    --n_shot_prompting 0 \
    --pass_k 10 \
    --samples_interval all
